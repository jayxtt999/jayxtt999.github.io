<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="https://newzone.top/rss.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <atom:link href="https://newzone.top/rss.xml" rel="self" type="application/rss+xml"/>
    <title>我的笔记</title>
    <link>https://newzone.top/</link>
    <description>开源工具、效率方法、心理学探索的自我提升笔记，记录并输出一切能让自己提升的知识。</description>
    <language>zh-CN</language>
    <pubDate>Tue, 04 Apr 2023 08:49:31 GMT</pubDate>
    <lastBuildDate>Tue, 04 Apr 2023 08:49:31 GMT</lastBuildDate>
    <generator>vuepress-plugin-feed2</generator>
    <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
    <copyright>Copyright by 清顺</copyright>
    <image>
      <title>我的笔记</title>
      <url>https://newzone.top/logo.svg</url>
      <link>https://newzone.top/</link>
    </image>
    <category>工具</category>
    <item>
      <title>零基础入门 Stable Diffusion - 无需显卡把 AI 绘画引擎搬进家用电脑</title>
      <link>https://newzone.top/posts/2022-09-05-stable_diffusion_ai_painting.html</link>
      <guid>https://newzone.top/posts/2022-09-05-stable_diffusion_ai_painting.html</guid>
      <source url="https://newzone.top/rss.xml">零基础入门 Stable Diffusion - 无需显卡把 AI 绘画引擎搬进家用电脑</source>
      <description>我从小特别羡慕会画画的伙伴。他们能够将心中的想法画出来，而我最高水平的肖像画是丁老头。但在接触 Stable Diffusion 之后，我感觉自己脱胎换骨，给自己贴上了「会画画」的新标签。 丁老头进化旅程 Stable Diffusion 是一个「文本到图像」的人工智能模型，也是唯一一款开源且能部署在家用电脑（对硬件要求不高）上的 AI 绘图工具。使用 Stable Diffusion，你可以在拥有 6GB 显存显卡，16GB 内存或只依赖 CPU 的电脑上生成图像，并且仅需几秒钟的时间，无需进行预处理或后处理。</description>
      <category>工具</category>
      <pubDate>Mon, 05 Sep 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>我从小特别羡慕会画画的伙伴。他们能够将心中的想法画出来，而我最高水平的肖像画是丁老头。但在接触 Stable Diffusion 之后，我感觉自己脱胎换骨，给自己贴上了「会画画」的新标签。</p>
<figure><img src="https://tc.seoipo.com/2022-09-04-11-53-20.png" alt="" tabindex="0" loading="lazy"><figcaption>丁老头进化旅程</figcaption></figure>
<p>Stable Diffusion 是一个「文本到图像」的人工智能模型，也是唯一一款开源且能部署在家用电脑（对硬件要求不高）上的 AI 绘图工具。使用 Stable Diffusion，你可以在拥有 6GB 显存显卡，16GB 内存或只依赖 CPU 的电脑上生成图像，并且仅需几秒钟的时间，无需进行预处理或后处理。</p>
<p>想要体验 AI 绘图，你可以使用在线工具 <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion" target="_blank" rel="noopener noreferrer">Hugging Face</a>、<a href="https://beta.dreamstudio.ai/" target="_blank" rel="noopener noreferrer">DreamStudio</a> 或<a href="https://wenxin.baidu.com/moduleApi/ernieVilg" target="_blank" rel="noopener noreferrer">百度文心</a>。但相对于本地部署来说，Hugging Face 需要排队，生成一张图约 5 分钟；DreamStudio 可以免费生成 200 张图片，之后需要缴费；百度文心能用中文生成图片，但仍处于 beta 阶段，未正式商用。此外，这些在线工具的图片调整功能比较有限，无法批量生成图片，只适用于测试和体验。</p>
<p>如果你需要生成大量的 AI 图片，可以通过 Docker Desktop 将 <a href="https://github.com/AbdBarho/stable-diffusion-webui-docker" target="_blank" rel="noopener noreferrer">Stable Diffusion WebUI Docker</a> 部署到家用电脑上，从而实现免费的 AI 文字绘画，并摆脱在线工具的限制。对于 Mac 用户，推荐选择 Stable Diffusion 的 invoke 分支，如果在部署过程中出现错误，你可以参考 <a href="https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_MAC.md#doesnt-work-anymore" target="_blank" rel="noopener noreferrer">InvokeAI 文档</a>进行排查。对于 M1/M2 Mac 用户，推荐使用更简便的 <a href="https://www.charl-e.com/" target="_blank" rel="noopener noreferrer">CHARL-E</a> 或 <a href="https://sspai.com/post/75682" target="_blank" rel="noopener noreferrer">DiffusionBee</a>。</p>
<figure><img src="https://tc.seoipo.com/2022-09-05-16-22-45.png" alt="" tabindex="0" loading="lazy"><figcaption>Stable Diffusion 部署流程</figcaption></figure>
<p>以 Windows 平台为例，本文将依次介绍 Docker 环境配置、Stable Diffusion 安装及基本使用方法。</p>
<h2> Docker 环境配置</h2>
<p>本方案基于 Docker 配置，Docker 实质上是在运行的 Linux 系统中创建了一个隔离的文件环境。因此，Docker 必须部署在基于 Linux 内核的系统上。<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><a class="footnote-anchor" id="footnote-ref1"> 对于 Mac 用户，无需特别配置即可使用。而对于 Windows 用户，若想部署 Docker，则需要安装一个虚拟 Linux 环境，<strong>配置 WSL 或启用 Hyper-V 二选一</strong>。我推荐使用 Windows 子系统 WSL，它需要占用系统盘 30G 的空间。</a></p><a class="footnote-anchor" id="footnote-ref1">
</a><h3><a class="footnote-anchor" id="footnote-ref1"></a> 安装 WSL</h3>
<p>在管理员 PowerShell 输入命令 <code>wsl --install</code>，之后终端会默认安装 Ubuntu。系统下载时间较长，注意别关机。<sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup><a class="footnote-anchor" id="footnote-ref2"> 安装 Ubuntu 完成后，按提示设置 Ubuntu 账户和密码。</a></p><a class="footnote-anchor" id="footnote-ref2">
</a><h3><a class="footnote-anchor" id="footnote-ref2"></a> 启用 Hyper-V</h3>
<p>以管理员身份打开 PowerShell 控制台，输入命令 <code>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All</code>。<sup class="footnote-ref"><a href="#footnote3">[3]</a><a class="footnote-anchor" id="footnote-ref3"></a></sup><a class="footnote-anchor" id="footnote-ref3"> 重启电脑后，将开启 Hyper-V。</a></p><a class="footnote-anchor" id="footnote-ref3">
</a><h3><a class="footnote-anchor" id="footnote-ref3"></a> Linux 路径（Windows）</h3>
<p>配置 WebUI Docker 要进入 Linux 环境，因此 Windows 用户需要将其路径转换为 Linux 路径。而 Mac 和 Linux 用户则可以忽略此步骤。</p>
<p>假设容器位于 <code>D:\Desktop\stable-diffusion-webui-docker</code>：</p>
<ol>
<li>把磁盘符号改为小写，转换为 <code>d:\Desktop\stable-diffusion-webui-docker</code></li>
<li>添加 <code>/mnt/</code> 前缀，转换为 <code>/mnt/d:\Desktop\stable-diffusion-webui-docker</code>。因为 Windows 本地磁盘是挂载在 Linux 的 mnt 目录下的。</li>
<li>将反斜扛 <code>\</code> 替换为 <code>/</code>。最终得到 Linux 路径 <code>/mnt/d:/Desktop/stable-diffusion-webui-docker</code>。</li>
</ol>
<h2> 配置 Stable Diffusion</h2>
<h3> 安装 Docker Desktop</h3>
<p>按平台选 <a href="https://docs.docker.com/get-docker/" target="_blank" rel="noopener noreferrer">Docker Desktop</a> 版本，安装后点击左侧的 Add Extensions，推荐安装 Disk usage 扩展，这将便于管理 Docker 的存储空间。</p>
<h3> 下载 WebUI Docker</h3>
<p>下载 <a href="https://github.com/AbdBarho/stable-diffusion-webui-docker/releases/" target="_blank" rel="noopener noreferrer">Stable Diffusion WebUI Docker 配置包</a>或<a href="https://www.aliyundrive.com/s/EKmK7MGrHdn" target="_blank" rel="noopener noreferrer">阿里云盘聚合版</a>（定期更新），然后将其解压到指定路径。聚合版包括相关依赖和模型，因此文件较大。如果需要更新 Stable Diffusion WebUI Docker，你可以按照上述步骤重新构建容器。</p>
<h3> 分支介绍</h3>
<p>目前，Stable Diffusion 有 sygil、auto、auto-cpu 和 invoke 四个分支。如果需要更换分支，可以修改镜像构建命令 <code>docker compose --profile [ui] up --build</code> 中的 <code>[ui]</code>，将其替换为所需的镜像名即可。原先的 <code>hlky</code> 分支已经更名为 <code>sygil</code>，<code>lstein</code> 分支更名为 <code>invoke</code>。</p>
<ul>
<li><strong>sygil</strong>：界面直观，最高分辨率为 1024x1024，镜像构建命令为 <code>docker compose --profile sygil up --build</code>。</li>
<li><strong>auto</strong>（推荐）：设置模块最丰富，显示绘画过程，支持随机插入艺术家、参数读取和否定描述，最高分辨率为 2048x2048（高分辨率对显存要求更高），镜像构建命令为 <code>docker compose --profile auto up --build</code>。默认使用 6GB 以上的显存，如果你的显卡内存较低，则将配置中的 <code>--medvram</code> 改为 <code>--lowvram</code>。A 卡用户注意修改<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs#running-inside-docker" target="_blank" rel="noopener noreferrer">显卡设置</a>。</li>
<li><strong>auto-cpu</strong>：唯一不依赖显卡的分支。如果没有符合要求的显卡，可以使用 CPU 模式，内存配置需满足 16G 以上，构建镜像的命令为 <code>docker compose --profile auto-cpu up --build</code>。</li>
<li><strong>invoke</strong>：cli 端非常成熟，WebUI 端参数较少，能自动读取图片记录，适合无进阶需求的新手和 Mac 用户使用，镜像构建命令为 <code>docker compose --profile invoke up --build</code>。</li>
</ul>
<h3> 构建 Stable Diffusion</h3>
<p>在启动 Docker Desktop 后，打开 WSL（Ubuntu）或 Mac 终端，输入路径切换命令 <code>cd /mnt/d/Desktop/stable-diffusion-webui-docker</code>（路径为 Stable Diffusion WebUI Docker 解压文件目录）。接着，输入以下的部署命令：</p>
<div class="language-bash line-numbers-mode" data-ext="sh"><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="https://tc.seoipo.com/2022-09-04-18-32-31.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>
<p>等待构建完成后，在终端中会提示访问 <code>http://localhost:7860/</code>，你就可以在本地电脑上用 AI 生成图片了。<sup class="footnote-ref"><a href="#footnote4">[4]</a><a class="footnote-anchor" id="footnote-ref4"></a></sup></p><a class="footnote-anchor" id="footnote-ref4">
</a><h2><a class="footnote-anchor" id="footnote-ref4"></a> 使用说明</h2>
<p>以下示例以 sygil 分支为例，其他分支的主题界面略有不同，但在功能上并没有根本性的差异。</p>
<h3> 启动 Stable Diffusion</h3>
<ol>
<li>打开 Docker Desktop。</li>
<li>在 Containers 中选中分支容器，点击启动。</li>
<li>浏览器中访问 <code>http://localhost:7860/</code>。</li>
</ol>
<figure><img src="https://tc.seoipo.com/2022-09-04-17-06-27.png" alt="" tabindex="0" loading="lazy"><figcaption>Docker Desktop 界面</figcaption></figure>
<h3> Text-to-Image</h3>
<p>Text-to-Image 是 Stable Diffusion 依据文字描述来生成图像的方法。对于崇尚空间结构的画作类型，如风景、创意画等，推荐使用竖图或横图。对于人像类画作，推荐使用 1:1 的方形图像，否则可能会出现多个人脸叠加的情况。生成的图片分辨率受到一定限制，你可以使用 Upscale 对结果图片进行放大处理。</p>
<figure><img src="https://tc.seoipo.com/2022-09-05-08-28-23.png" alt="" tabindex="0" loading="lazy"><figcaption>Text-to-Image 界面</figcaption></figure>
<p>默认情况下使用的是 Simple 简单模式。如果你想要使用更多的功能，你可以点击右侧的 Advanced 按钮，进入进阶选项。在进阶选项中，你可以使用场景矩阵、面部修复和分辨率放大等多种高级功能。</p>
<h3> Image-to-Image</h3>
<p>Image-to-Image 是依据文字描述和输入源图来生成相关图像。如果输入源图是 Text-to-Image、素描或结构画，该模式可充分填充图像细节。而如果输入源图是细节充分的照片，生成的结果与原图差异较大。此外，你还可以限定区域来生成图像，这非常适合进行图像修改。</p>
<figure><img src="https://tc.seoipo.com/2022-09-04-15-39-00.png" alt="" tabindex="0" loading="lazy"><figcaption>Image-to-Image 界面</figcaption></figure>
<p>CLIP interrogator 会根据图像来生成文字描述。Denoising Strength 指与原图的差异度，建议设置在 0.75-0.9 之间。若要魔改图片，可将 Denoising Strength 设为 0.5 或以下。下图中的 Denoising Strength 只有 0.44，整体图片结构及要素未变，但结果如何，你看到了。</p>
<figure><img src="https://tc.seoipo.com/2022-09-04-15-40-26.png" alt="" tabindex="0" loading="lazy"><figcaption>超级魔改图片</figcaption></figure>
<p>Image-to-Image 还可以用来移除、替换或修复图像，甚至可以将源图作为结果图的一部分，利用 Stable Diffusion 扩展绘画。</p>
<h3> Image Lab</h3>
<p>Image Lab 有批量修正面孔和放大图片分辨率的功能。</p>
<p>Fix Faces 是通过 GFPGAN 模型来改善图片中的面孔，Effect strength 滑块可以控制效果的强度。但实际效果别报太高期许，下图右侧开启了 Fix Faces，只能说勉强有了五官。</p>
<figure><img src="https://tc.seoipo.com/2022-09-04-15-47-14.png" alt="" tabindex="0" loading="lazy"><figcaption>A woman flying in the air laughing</figcaption></figure>
<p>Upscale 可以通过 RealESRGAN、GoBIG、Latent Diffusion Super Resolution 和 GoLatent 四种模型来放大图片分辨率。其中，RealESRGAN 有普通和卡通两种模式，你可以根据需要进行选择。放大图片主要消耗 CPU 和内存资源。</p>
<h2> 参数解释</h2>
<h3> Classifier Free Guidance</h3>
<p>Classifier Free Guidance (CFG) 的默认值为 7。数字越小，创作自由度越高，模型与 Prompt 相关性越低。CFG 参数不影响所需的 VRAM 或生成时间。</p>
<ul>
<li>CFG 2-6：虽然有创意，但可能不符合提示。</li>
<li>CFG 7-10：这些提示适用于大多数情况，既富有创意又具有指导性。</li>
<li>CFG 10-15：当你确信 Prompt 足够好、足够具体时可以使用。</li>
<li>CFG 16-20：除非提示非常详细，否则不建议使用。这可能会影响连贯性和质量。</li>
</ul>
<h3> Step</h3>
<p>Step（采样步长/精度）的默认值为 50。Stable Diffusion 通过充满噪音的画布开始创建图像，并逐步去噪以达到最终输出。Step 参数控制这些去噪步骤的数量。通常情况下，越高越好。对于初学者来说，建议使用默认值。Step 参数不影响所需的 VRAM，但 Step 数值的变化会与生成图像的时间成正比。</p>
<h3> Seed</h3>
<p>Seed（种子）的默认值为 -1，代表随机值。Seed 是控制初始噪声的数字，在其他参数固定的情况下，每次生成的图像都会不同，这就是种子的作用。如果你保持提示、种子和所有其他参数不变，你可以得到相同的结果。如果一个 Seed 生成了高质量图片，保存该 Seed 并将其应用到其他图片上，以保持高质量。</p>
<h3> Sampler</h3>
<p>Sampling method/Diffusion Sampler（扩散采样器）是用来在生成图像过程中对图像进行去噪的方法。由于不同的扩散采样器在计算图像下一步的方式不同，因此它们需要不同的持续时间和步骤来生成可用的图像。建议初学者使用 DDIM，因为它速度快，通常只需要 10 步就能生成好的图像，因此可以很容易和快速地进行试验和改进。</p>
<h2> 文字描述图像</h2>
<p>Stable Diffusion 通过英文文字内容来描述场景或物体，以此来决定生成的图像中会出现什么。文字描述是决定图像生成质量的关键因素。<sup class="footnote-ref"><a href="#footnote5">[5]</a><a class="footnote-anchor" id="footnote-ref5"></a></sup></p><a class="footnote-anchor" id="footnote-ref5">
</a><p><a class="footnote-anchor" id="footnote-ref5">样例：<code>A beautiful painting {画作种类} of a singular lighthouse, shining its light across a tumultuous sea of blood {画面描述} by greg rutkowski and thomas kinkade {画家/画风}, Trending on artstation {参考平台}, yellow color scheme {配色}</code>。<sup class="footnote-ref"></sup></a><a href="#footnote6">[6]</a><a class="footnote-anchor" id="footnote-ref6"></a></p><a class="footnote-anchor" id="footnote-ref6">
</a><h3><a class="footnote-anchor" id="footnote-ref6"></a> 常规描述</h3>
<ol>
<li>输入图像的对象、主体，比如一只熊猫、一个持剑的战士，<strong>不要描述动作、情绪和事件</strong>；<sup class="footnote-ref"><a href="#footnote7">[7]</a><a class="footnote-anchor" id="footnote-ref7"></a></sup></li><a class="footnote-anchor" id="footnote-ref7">
<li><strong>图像种类</strong>：一幅画（a painting of + raw prompt）还是一张照片（a photograph of + raw prompt），或者 Watercolor（水彩）、Oil Paint（油画）、Comic（漫画）、Digital Art（数码艺术）、Illustration（插画）、realistic painting（写实画）、photorealistic（写实照片）、Portrait photogram（肖像照）、Low Poly（低面建模）、3D Item Rende（三维渲染）、sculpture (雕塑) 等等，图像种类可以叠加。</li>
<li><strong>画家/画风</strong>：建议混合多个画家的风格，比如 <code>Studio Ghibli, Van Gogh, Monet</code>，或描述风格种类，比如 <code>very coherent symmetrical artwork</code>，将作品结构设为「连贯且对称」。</li>
<li><strong>色调</strong>：yellow color scheme 指整个画面的主色调为黄色。</li>
<li><strong>参考平台</strong>：Trending on ArtStation，也可以替换为「Facebook」「Pixiv」「Pixbay」等。
<img src="https://tc.seoipo.com/2022-09-16-22-33-26.png" alt="" title="相同参数下，不同平台生成的图片" loading="lazy"></li>
</a></ol><a class="footnote-anchor" id="footnote-ref7">
</a><h3><a class="footnote-anchor" id="footnote-ref7"></a> 特征描述</h3>
<p>除画面主体外，可以用其他具象物体和形容词来填充画面细节。描述词要具体，讲出你要的物体和它的特征。</p>
<ul>
<li>次要元素：物体不要太多，两到三个就好。若要特别强调某个元素，可以加很多括号或者惊叹号，比如 <code>beautiful forest background, desert!!, (((sunset)))</code> 中会优先体现「desert」和「sunset」元素。</li>
<li>人物特征：<code>detailed gorgeous face, delicate features, elegant, Googly Eyes, Bone, big tits, silver hair, olive skin, Mini smile</code>；</li>
<li>特定润色：<code>insanely detailed and intricate, gorgeous, surrealism, smooth, sharp focus, Painting, Digital Art, Concept Art, Illustration, Artstation, in a symbolic and meaningful style, 8K</code>；</li>
<li>光线描述：<code>Natural Lighting, Studio lighting, Cinematic Lighting, Crepuscular Rays, X-Ray, Backlight</code>，或逼真光照 <code>Unreal Engine</code>；</li>
<li>镜头视角：<code>Cinematic, Magazine, Golden Hour, F/22, Depth of Field, Side-View</code>，虚化背景 <code>Bokeh</code>；</li>
<li>画面质量：<code>professional, award winning, breathtaking, groundbreaking, superb, outstanding</code>；</li>
<li>其他描述：细节和纹理、物体占据画面的大小、年代、渲染 / 建模工具等，比如 Vivid Colors（艳丽色彩）。</li>
</ul>
<h3> prompt 权重</h3>
<p>假设你在提示词中使用了 <code>mountain</code>，生成的图像很可能会有树。但如果你想要生成没有树的山的图像，可以使用 <code>mountain | tree:-10</code>。其中 <code>tree:-10</code> 表示对于树的权重非常负，因此生成的图像中不会出现树。通过权重词，我们还能生成更复杂的图像，例如 <code>A planet in space:10 | bursting with color red, blue, and purple:4 | aliens:-10 | 4K, high quality</code>。<sup class="footnote-ref"><a href="#footnote8">[8]</a><a class="footnote-anchor" id="footnote-ref8"></a></sup></p><a class="footnote-anchor" id="footnote-ref8">
<p>Prompt 中的词语顺序代表其权重，越靠前权重越大。如若某物未出现在图像中，可以将该名词放在首位。</p>
</a><h3><a class="footnote-anchor" id="footnote-ref8"></a> 否定提示</h3>
<p>auto/auto-cpu 分支中可以设置 Negative prompt（否定提示），以避免画面中出现指定元素。</p>
<ul>
<li>修正畸形：<code>disfigured, deformed hands, blurry, grainy, broken, cross-eyed, undead, photoshopped, overexposed, underexposed, lowres, bad anatomy, bad hands, extra digits, fewer digits, bad digit, bad ears, bad eyes, bad face, cropped: -5</code>。</li>
<li>避免裸体：<code>nudity, bare breasts</code>。</li>
<li>避免黑白照：<code>black and white,monochrome</code>。</li>
</ul>
<h3> prompt 参考</h3>
<p>除画面主体描述外，其他要素并非必须。如果你只是简单尝试，输入主体「apples」即可。</p>
<p>如果你不知道生成什么图像，可以使用 <a href="https://promptomania.com/stable-diffusion-prompt-builder/" target="_blank" rel="noopener noreferrer">promptoMANIA</a> 、<a href="https://weirdwonderfulai.art/resources/disco-diffusion-modifiers/" target="_blank" rel="noopener noreferrer">WEIRD WONDERFUL AI ART</a> 按提示组合描述，或参考 AI 图库 <a href="https://prompthero.com/" target="_blank" rel="noopener noreferrer">PromptHero</a> 和 <a href="https://openart.ai/" target="_blank" rel="noopener noreferrer">OpenArt</a> 上其他人分享的成品图和描述文案，比如</p>
<blockquote>
<p>goddess close-up portrait skull with mohawk, ram skull, skeleton, thorax, x-ray, backbone, jellyfish phoenix head, nautilus, orchid, skull, betta fish, bioluminiscent creatures, intricate artwork by Tooth Wu and wlop and beeple, highly detailed, digital painting, Trending on artstation, very coherent symmetrical artwork, concept art, smooth, sharp focus, illustration, 8k</p>
</blockquote>
<h2> Prompt matrix</h2>
<p>Prompt matrix 是 sygil 分支的功能，可以按不同条件组合生成多张相关但不同的画面，适合用于制作视频素材。<sup class="footnote-ref"><a href="#footnote9">[9]</a><a class="footnote-anchor" id="footnote-ref9"></a></sup><a class="footnote-anchor" id="footnote-ref9"> 此时，批次数量的设置会被忽略。如果你对将图像转化为视频有兴趣，可以尝试使用 </a><a href="https://github.com/HelixNGC7293/DeforumStableDiffusionLocal" target="_blank" rel="noopener noreferrer">Deforum Stable Diffusion Local Version</a>。</p>
]]></content:encoded>
    </item>
    <item>
      <title>找不到字幕？Whisper 让不懂外语的你也能看懂日剧</title>
      <link>https://newzone.top/posts/2022-11-18-whisper_ai_subtitles.html</link>
      <guid>https://newzone.top/posts/2022-11-18-whisper_ai_subtitles.html</guid>
      <source url="https://newzone.top/rss.xml">找不到字幕？Whisper 让不懂外语的你也能看懂日剧</source>
      <description>从大学开始，我看日剧十几年了，但日语毫无进步，只能听懂几句耳熟能详的句子，看国外电影全靠字幕组。曾经我想过学日语，报了暑期班，但成绩被七岁的小妹妹同学吊打。然后，我就被自己的语言能力说服了，想着这辈子都离不开字幕组。这种情况一直持续着，直到我测试视频剪辑工具 AutoCut 时遇到了 Whisper。 Whisper 是今年 9 月被 OpenAI 开源的自动语音识别系统，除了可以用于语音识别，Whisper 还能实现多种语言的转录，以及将这些语言翻译成英语。「语言识别」「转录」听起来特别唬人，但 transcribe（转录）指将语音转为文字，Whisper 会为音视频生成带时间轴的字幕文件，是支持 99 种语言 AI 字幕工具。</description>
      <category>工具</category>
      <pubDate>Fri, 18 Nov 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>从大学开始，我看日剧十几年了，但日语毫无进步，只能听懂几句耳熟能详的句子，看国外电影全靠字幕组。曾经我想过学日语，报了暑期班，但成绩被七岁的小妹妹同学吊打。然后，我就被自己的语言能力说服了，想着这辈子都离不开字幕组。这种情况一直持续着，直到我测试视频剪辑工具 AutoCut 时遇到了 Whisper。</p>
<p>Whisper 是今年 9 月被 OpenAI 开源的自动语音识别系统，除了可以用于语音识别，Whisper 还能实现多种语言的转录，以及将这些语言翻译成英语。「语言识别」「转录」听起来特别唬人，但 transcribe（转录）指将语音转为文字，Whisper 会为音视频生成带时间轴的字幕文件，是<strong>支持 99 种语言 AI 字幕工具</strong>。</p>
<p>虽然与 Stable Diffusion 同样归属 AI 工具，但 Whisper 安装非常简单，终端执行两行代码安装 Whisper 和 FFmpeg 即可使用。如果你不清楚如何安装 FFmpeg，可参考<a href="https://newzone.top/posts/2022-11-03-ffmpeg_screen_recording.html#%E9%85%8D%E7%BD%AE-ffmpeg" target="_blank" rel="noopener noreferrer">FFmpeg 配置步骤</a>。这部分我不多做赘述，具体可以看<a href="https://github.com/openai/whisper" target="_blank" rel="noopener noreferrer">Whisper 官方文档</a>。</p>
<div class="language-bash line-numbers-mode" data-ext="sh"><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>接下来，我会分享如何使用 Whisper 为外语视频自动生成字幕，以日本综艺节目「中森明菜デビュー 40 周年 女神の熱唱！喝采は今も」为例。</p>
<h2> 音视频转录</h2>
<p>在文件所在目录下打开终端，运行 <code>whisper jp.mp4</code> 即可执行音视频转录。测试视频名原本为日语，我改为「jp.mp4」，原因是我系统中只装了中英语言包，使用其他语言作为命令会出现 Invalid argument 报错，从而导致转录失败。Whisper 的媒体分析环节调用了 FFmpeg，所以主流音视频格式均被支持。</p>
<figure><img src="https://tc.seoipo.com/2022-11-18-09-25-29.png" alt="" tabindex="0" loading="lazy"><figcaption>whisper 命令</figcaption></figure>
<p>视频时长 90 分钟，我使用 3080Ti 显卡转录，用时 10 分钟。转录过程中不要玩游戏，也不要进行直播等吃显存的行为，否则容易显存不足无法继续。Whisper 对设备要求不高，不过设备会决定转录时长和你能使用的转录模型。如果你使用 CPU 转录，时间会增加 5-10 倍。</p>
<p>转录完成后，Whisper 将生成原生字幕文件，日语视频会被转录为日语字幕，西班牙语视频会得到西班牙语字幕。</p>
<h2> 字幕翻译</h2>
<p>通过 Whisper 获得原生字幕后，接着要将其翻译为中文。这一步需借助 SubtitleEdit Online，它支持免费在线翻译字幕，可使用 Google 和 Yandex 两种翻译引擎。<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup></p><a class="footnote-anchor" id="footnote-ref1">
</a><ol><a class="footnote-anchor" id="footnote-ref1">
</a><li><a class="footnote-anchor" id="footnote-ref1">打开 </a><a href="https://www.nikse.dk/subtitleedit/online" target="_blank" rel="noopener noreferrer">SubtitleEdit Online</a>，点击「Subtitle」&gt;「Open...」，选择要导入的字幕文件。</li>
<li>点击「Auto-translate」，选择翻译引擎，然后在弹出窗口中选择字幕要翻译的语言，并<strong>将页面拖动到最下方</strong>（非常重要），确定所有文字都被翻译后点击 OK 按钮。</li>
<li>点击「Subtitle」&gt;「Save/download...」，即可保存翻译好的字幕文件。</li>
</ol>
<p>除了网页翻译字幕，本地端的神经机器翻译也是种好选择。macOS 用户推荐使用 <a href="https://github.com/argosopentech/argos-translate" target="_blank" rel="noopener noreferrer">Argos Translate</a>，这是基于 OpenNMT 的开源神经机器翻译。如果你的动手能力较强，可以尝试 <a href="https://github.com/Helsinki-NLP/Opus-MT" target="_blank" rel="noopener noreferrer">Opus-MT</a>。不管用哪种方式，都是将字幕以文本方式导出，复制到翻译引擎中翻译，即可得到不同于 Google Translate 的翻译结果。</p>
<h2> Whisper 进阶命令</h2>
<h3> task</h3>
<p><code>--task</code> 分为 transcribe（语音转录）和 translate。Whisper 默认使用 <code>--task transcribe</code> 模式，将语音转录为对应的语言字幕。<code>--task translate</code> 是所有语言翻译为英文，目前尚未支持翻译为其他语言。</p>
<h3> language</h3>
<p><code>--language</code> 是设置语音转录的语种，支持语种范围查看 <a href="https://github.com/openai/whisper/blob/main/whisper/tokenizer.py" target="_blank" rel="noopener noreferrer">tokenizer.py</a>，比如指定日语 <code>--language japanese</code>。如果你没指定语种，Whisper 会截取音频的前 30 秒来判断语种。</p>
<p>如果指定语种与文件中的语种并不相同，Whisper 会强制翻译，但 10 分钟以上的音视频会出现大量的重复无意义字幕。<sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup><a class="footnote-anchor" id="footnote-ref2"> 假设你把日语视频的转录语言设为汉语，前 8 分钟 Whisper 会正确转录到中文，但 8 分钟后的转录字幕会一直重复，并与实际片段无关。</a></p><a class="footnote-anchor" id="footnote-ref2">
</a><h3><a class="footnote-anchor" id="footnote-ref2"></a> model</h3>
<p><code>--model</code> 指 Whisper 的转录模型，转录效果为 tiny &lt; base &lt; small &lt; medium &lt; large，默认使用 small。添加参数 <code>--model medium</code> 或 <code>--model large</code> 可以切换到更大的模型，但转录时间也会变长。如果你是对英文视频进行转录，则在模型参数上添加后缀 <code>.en</code>，能提升转录速度。</p>
<table>
<thead>
<tr>
<th style="text-align:center">模型</th>
<th style="text-align:center">大小</th>
<th style="text-align:center">单英语模型</th>
<th style="text-align:center">多语言模型</th>
<th style="text-align:center">最低显存</th>
<th style="text-align:center">转录速率</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">tiny</td>
<td style="text-align:center">39 M</td>
<td style="text-align:center"><code>tiny.en</code></td>
<td style="text-align:center"><code>tiny</code></td>
<td style="text-align:center">~1 GB</td>
<td style="text-align:center">~32x</td>
</tr>
<tr>
<td style="text-align:center">base</td>
<td style="text-align:center">74 M</td>
<td style="text-align:center"><code>base.en</code></td>
<td style="text-align:center"><code>base</code></td>
<td style="text-align:center">~1 GB</td>
<td style="text-align:center">~16x</td>
</tr>
<tr>
<td style="text-align:center">small</td>
<td style="text-align:center">244 M</td>
<td style="text-align:center"><code>small.en</code></td>
<td style="text-align:center"><code>small</code></td>
<td style="text-align:center">~2 GB</td>
<td style="text-align:center">~6x</td>
</tr>
<tr>
<td style="text-align:center">medium</td>
<td style="text-align:center">769 M</td>
<td style="text-align:center"><code>medium.en</code></td>
<td style="text-align:center"><code>medium</code></td>
<td style="text-align:center">~5 GB</td>
<td style="text-align:center">~2x</td>
</tr>
<tr>
<td style="text-align:center">large</td>
<td style="text-align:center">1550 M</td>
<td style="text-align:center">N/A</td>
<td style="text-align:center"><code>large</code></td>
<td style="text-align:center">~10 GB</td>
<td style="text-align:center">1x</td>
</tr>
</tbody>
</table>
<p>上方表格是 Whisper 官方提供信息，但目前模型实际增大 50%-100%，要求也增加了，仅作参考。</p>
<h3> 辅助参数</h3>
<ul>
<li><code>--device</code> 指 whisper 运行算法所用的硬件，默认为 cuda 即显存，或者指定 <code>--device cpu</code> 。特别当你显存不够，又想使用较大模型时，推荐指定 CPU 转录。</li>
<li><code>--temperature</code> temperature 决定了生成模型的贪婪程度，默认为 0。如果 temperature 低，概率最高的词将远高于其他低概率，模型将可能输出最正确的文本，变化很小。如果 temperature 较高，该模型会输出概率较高的其他单词，而不是概率最高的单词，生成的文本将更加多样化，但有更高的可能性出现语法错误和生成无意义的文本。</li>
<li><code>--temperature_increment_on_fallback</code> 当解码失败时，回推时要增加的 temperature，默认为 0.2。</li>
<li><code>--best_of</code> temperature 不为零时的侯选个数，默认为 5。</li>
<li><code>--beam_size</code> temperature 为零时，number of beams in beam search，默认为 5。beam 直译是光束，但没理解具体意思，我简单理解其为侯选数。</li>
<li><code>--patience</code> 用于 beam decoding 的 patience value, as in <a href="https://arxiv.org/abs/2204.05424" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2204.05424</a>, the default (1.0) is equivalent to conventional beam search (default: None) simple length normalization by default (default: None)</li>
<li><code>--length_penalty</code> optional token length penalty coefficient (alpha) as in <a href="https://arxiv.org/abs/1609.08144" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1609.08144</a>, uses simple length normalization by default (default: None)</li>
<li><code>--suppress_tokens</code> 逗号分隔的标记 ID 列表，以便在采样过程中进行抑制; 默认为 -1，这会抑制除常见标点符号外的大多数特殊字符的出现。</li>
<li><code>--initial_prompt</code> 可选的文本提示，在命令首行出现，默认为空。</li>
<li><code>--condition_on_previous_text</code> 默认为 True，为下一个窗口提供模型之前的输出作为提示；禁用可能会使不同窗口的文本不一致，但模型变得不容易陷入失败循环。</li>
<li><code>--fp16</code> 是否启用半精度 fp16 进行推理运算，默认为 True，否则为单精度 fp32，运行时间延长。</li>
<li><code>--threads</code> 指定 CPU 运算的线程数，会取代 MKL_NUM_THREADS/OMP_NUM_THREADS (默认：0)</li>
</ul>
<h3> 幻听参数</h3>
<p>非英语视频的转录有时会出现幻听，即静默片段被识别出语音，或是转录结果与该片段无关。这些问题是由语气停顿参数引起的。幻听的解决方案是引入 <a href="https://github.com/snakers4/silero-vad" target="_blank" rel="noopener noreferrer">VAD</a>，但 VAD 对动手能力要求较高。如果你的视频转录出现了严重幻听，建议先尝试调节参数阈值。</p>
<ul>
<li><code>--no_speech_threshold</code> 无声识别的阈值，默认为 0.6。当 no_speech_threshold 高于阈值且 logprob_threshold 低于预设时，该片段将被标记为静默。对于非英语长视频来说，建议将其调低，否则经常出现大段的重复识别。</li>
<li><code>--logprob_threshold</code> 转录频次的阈值，默认为 -1.0。当 logprob_threshold 低于预设时，将不对该片段进行转录。建议修改为 None 或更低的值。</li>
<li><code>--compression_ratio_threshold</code> 压缩比的阈值，默认为 2.4。当 compression_ratio_threshold 高于预设时，将不对该片段进行转录。</li>
</ul>
<p><code>--no_speech_threshold 0.5 --logprob_threshold None --compression_ratio_threshold 2.2</code> 是我常用的参数，你可以按视频情况来调节，幻听参数放在转录命令后面。</p>
<h2> 转录成果</h2>
<p>「夜のヒットスタジオ・スペシャル」：</p>
]]></content:encoded>
    </item>
    <item>
      <title>为了帮你用好 ChatGPT，我做了一个「咒语库]</title>
      <link>https://newzone.top/posts/2023-02-27-chatgpt_shortcuts.html</link>
      <guid>https://newzone.top/posts/2023-02-27-chatgpt_shortcuts.html</guid>
      <source url="https://newzone.top/rss.xml">为了帮你用好 ChatGPT，我做了一个「咒语库]</source>
      <description>最近，关于 ChatGPT 的讨论越来越多，但大多数人仅仅将其视为一款聊天机器人，并从猎奇的角度去测试其人工智能的回答。然而，ChatGPT 不仅仅是一个猎奇的 AI 玩具，未来它将会成为必备生产工具。ChatGPT 之类的 AI 工具将用它巨大的语言知识库，为我们创造更多的价值。 ChatGPT 的回复质量取决于提示词（即 Prompt）。这通常是用户提供的问题或文本，以激活模型生成回复。简单来说，prompt 就是用户想要询问的内容，作为输入送到 ChatGPT 中，ChatGPT 会尝试理解这个输入，然后输出合适的回答或响应。通过优化提示词，可以使 ChatGPT 生成更加准确、有用的回复。为了能让 ChatGPT 成为生产力工具，我花大量时间逐个研究提示词的规则和范例，如 ChatGPT Prompt Examples、Awesome ChatGPT Prompts、Learn Prompting 等。我筛选出了 163 个 Prompts（提示词），仅记录它们的功能而非内容，这就让我的笔记超过了 5000 字。提示词目录也变得越来越长，即使将浏览器全屏，也无法完整显示。起初，我制作提示词目录是为了方便自己，但每次需要查找提示词时，我不得不依靠记忆。这些笔记反而成为了负担，拖累 ChatGPT 的工作效率。</description>
      <category>工具</category>
      <pubDate>Mon, 27 Feb 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[<p>最近，关于 ChatGPT 的讨论越来越多，但大多数人仅仅将其视为一款聊天机器人，并从猎奇的角度去测试其人工智能的回答。然而，ChatGPT 不仅仅是一个猎奇的 AI 玩具，未来它将会成为必备生产工具。ChatGPT 之类的 AI 工具将用它巨大的语言知识库，为我们创造更多的价值。</p>
<p>ChatGPT 的回复质量取决于提示词（即 Prompt）。这通常是用户提供的问题或文本，以激活模型生成回复。简单来说，prompt 就是用户想要询问的内容，作为输入送到 ChatGPT 中，ChatGPT 会尝试理解这个输入，然后输出合适的回答或响应。通过优化提示词，可以使 ChatGPT 生成更加准确、有用的回复。为了能让 ChatGPT 成为生产力工具，我花大量时间逐个研究提示词的规则和范例，如 <a href="https://platform.openai.com/examples" target="_blank" rel="noopener noreferrer">ChatGPT Prompt Examples</a>、<a href="https://github.com/f/awesome-chatgpt-prompts" target="_blank" rel="noopener noreferrer">Awesome ChatGPT Prompts</a>、<a href="https://learnprompting.org/" target="_blank" rel="noopener noreferrer">Learn Prompting</a> 等。我筛选出了 163 个 Prompts（提示词），仅记录它们的功能而非内容，这就让我的笔记超过了 5000 字。提示词目录也变得越来越长，即使将浏览器全屏，也无法完整显示。起初，我制作提示词目录是为了方便自己，但每次需要查找提示词时，我不得不依靠记忆。这些笔记反而成为了负担，拖累 ChatGPT 的工作效率。</p>
<p>为了更好地使用 ChatGPT，我将精选的提示词编入索引，根据领域和功能对其进行分类，添加针对提示词的标签筛选、关键词搜索、一键复制和中英文切换功能，创建了 ChatGPT Shortcut 项目。即使是初学者，你只需<strong>打开 <a href="https://newzone.top/chatgpt/" target="_blank" rel="noopener noreferrer">ChatGPT Shortcut</a>，复制提示词，稍加修改后发送给 ChatGPT</strong>，就能获得指定输出，让你的生产力加倍！</p>
<h2> 使用说明</h2>
<p>ChatGPT Shortcut 页面默认显示全部的提示词，页面分为标签区、搜索区和提示词展示区。</p>
<figure><img src="https://tc.seoipo.com/2023-02-28-10-30-20.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>
<h3> 标签筛选</h3>
<p>标签区按提示词的领域和功能进行划分，可根据不同场景和需求进行选择。与标签区右上方的「标签筛选规则切换」按钮配合使用，可进行多标签筛选。默认状态为 OR，即选中标签下的所有提示词。切换到 AND 后，将筛选出具备已选中的多个标签的提示词。</p>
<figure><img src="https://tc.seoipo.com/2023-02-28-10-31-01.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>
<h3> 关键词搜索</h3>
<p>关键词搜索范围包括提示词的标题、简介、内容和中文翻译。输入关键词后，提示词展示区将立即展示筛选出的内容。如果已选中标签，则关键词搜索仅限于标签筛选范围内。对于 PC 端，搜索框内容变化后，新的搜索结果会在 800 毫秒后显示。移动端则为即时刷新。</p>
<figure><img src="https://tc.seoipo.com/2023-02-28-10-31-10.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>
<h3> 展示区复制</h3>
<p>通过标签筛选和关键词搜索，点击卡片右上方的「复制」按钮即可获取提示词，将其粘贴到 ChatGPT 中，参考中文提示调整需求文本，即可得到指定领域的回复。如果提示词中的中文备注没有解释清楚，可以点击提示词的绿色标题查看来源网页。</p>
<figure><img src="https://tc.seoipo.com/2023-02-28-10-31-19.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>
<h3> 语言切换</h3>
<p>默认情况下，提示词内容会显示为英文。如果你想查看中文释义，可以点击提示词内容将其切换到中文，再次点击即可切回英文。请注意，语言切换只在文字上点击有效，点击空白区域无效。中文释义为机器翻译，仅供参考。</p>
<figure><img src="https://tc.seoipo.com/chatgptshortcut_encn.gif" alt="中英文切换" tabindex="0" loading="lazy"><figcaption>中英文切换</figcaption></figure>
<p>如果想让提示词默认显示为中文，你可以点击导航栏右侧的 <code>CN</code> 按钮。需要注意的是，即使切换到中文翻译，复制按钮也仅针对英文提示词复制。下方会有解释原因。</p>
<h2> 常见问题</h2>
<h3> 为什么提示词用英文？</h3>
<p>ChatGPT Shortcut 是为方便中文母语人士使用 ChatGPT 而创建的，但是提示词却全部是英文。这是因为相较于中文，ChatGPT 对英文的理解更为出色。即使是国内第一个对话式大型语言模型 MOSS，也承认 MOSS 的英文回答水平比中文高，建议使用英文。（MOSS 已不对外开放）</p>
<p>使用中文提示词可能会得到不错的结果，但是当你再次输入相同的中文提示时，结果可能与之前大相径庭。因为 ChatGPT 对中文的理解每次都不同，所以建议大家在生产力型提示词的输入中使用英文提示词，以保证输出效果。此外，英文提示词带来的回复也很可能是英文的，你可以在提示词结尾添加 <code>respond in Chinese</code>，将回复指定为中文。</p>
<h3> 中文搜索出错</h3>
<p>搜索功能基于 Docusaurus 的 showcase，存在 PC 端中文输入法焦点丢失问题。向 Docusaurus 反馈后，对方表示会尝试修复和 <code>FWIW, you should not be using Chinese anyway, since the showcase is not localized</code>。但问题始终没有解决。</p>
<p>因此，我将搜索组件分为移动端和 PC 端两类。移动端搜索逻辑保持不变，而屏幕宽度阈值 768px 以上的 PC 端浏览引入 <code>debounce</code> 函数解决中文输入问题。但这在 PC 端产生两个问题：一是中文输入需在 800 毫秒内完成；二是 PC 端搜索刷新从即时变为 800 毫秒延迟。若你有更好的解决方案，欢迎提供反馈。</p>
<h3> 输出虚假信息</h3>
<p>ChatGPT 虽然非常强大，但并不是万能的。有时它会输出虚假信息。例如，当我需要将上百条信息录入到 ChatGPT Shortcut 中时，我让 ChatGPT 按指定格式转换数据。但是在转换过程中，我发现其中一些信息被 ChatGPT 误写。例如，在文本中一条标签是 <code>movie critic</code>，而 ChatGPT 将其更改为 <code>film critic</code>。尽管这在文本中不会造成什么影响，但放在代码中会报错。因此，在使用 ChatGPT 时，务必检查其输出内容。</p>
<h3> 提示词不好用</h3>
<p>所有提示词均来自互联网，会定期进行更新。虽然我测试过每一条提示词，但实际效果可能因需求而有所偏差。你可以参考页面和 <a href="https://platform.openai.com/examples" target="_blank" rel="noopener noreferrer">ChatGPT Prompt Examples</a> 进行调整。如果你发现任何错误、有创意的想法或有好的提示词，欢迎<a href="https://github.com/rockbenben/ChatGPT-Shortcut/discussions/11" target="_blank" rel="noopener noreferrer">反馈和投稿</a>。</p>
<p>此外，提示词不仅能用于工作生产，更重要的是帮助您开拓思路，发散思维，从多个角度考虑问题，并解决人们在思考时容易忽略的问题。</p>
<h2> 为什么执着于 ChatGPT？</h2>
<p>家人看到我每天把大量时间花在 ChatGPT，实际上并不能理解。因为这看起来跟我的工作关系不大。ChatGPT 帮我节省的时间远少于我的投入，帮我写的代码和文章都需要大幅修改，而查找的资料也基本上只是基础知识，而对于具体的问题我还需要去专业网站进行查询。那么，ChatGPT 究竟有什么用呢？等它成熟了再去使用不好吗？</p>
<p>但是，我们需要明确的是，使用 ChatGPT 等 AI 工具可以提高我们的工作效率和解放我们的时间，让我们可以更专注于创造性的工作和创新性的思考。比如，ChatGPT 在文章修订、语气转换、语音录入、代码解释、创意思维等方面已经成为我不可或缺的工具。虽然 ChatGPT 目前的功能和表现还有待提高和改进，但它毕竟是未来工具的一部分，是我们不断提高自己和适应未来的必要工具。我相信随着时间的推移，ChatGPT 的表现会越来越优秀，让我们的工作更高效，更具有创造性。</p>
<h2> 最后</h2>
<p>目前，ChatGPT 已经有 1 亿用户，但这仅仅是 80 亿人口中很小的一部分。无论你身处哪个行业，你使用 ChatGPT 都代表着你在行业前沿。尽管你可能认为这看起来似乎与你的行业无关，但使用它就代表着你比别人更早地迈出了这一步，可以探索更多的可能性。</p>
<p>我并不期待 ChatGPT Shortcut 成为完美的工具，而是希望它能为大家推开使用 AI 的一道门缝。我希望让更多人了解和使用 ChatGPT，摆脱对其聊天机器人的刻板印象，以提高工作效率。因为我相信，在未来，ChatGPT 和其他 AI 工具将扮演越来越重要的角色，成为我们生产力的强大工具。</p>
]]></content:encoded>
      <enclosure url="https://tc.seoipo.com/2023-02-28-10-30-20.png" type="image/png"/>
    </item>
  </channel>
</rss>